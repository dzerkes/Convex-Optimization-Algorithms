{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Optimization Exercise  4 ~ Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import diags\n",
    "from numpy import linalg\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def f_x(x,A,b):\n",
    "    f = (1/2)*np.dot(np.dot(x.T,A),x) - np.dot(b.T,x)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 7 7 ... 7 7 8]\n",
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "dim = 10**4 # dimensions needed\n",
    "main_diag = [9 for i in range(dim)] # 9...9 main diagonal\n",
    "low_upper_diag = [-1 for i in range(dim)] # 1st up and 1st down diagonal\n",
    "diagonals = [main_diag,low_upper_diag,low_upper_diag] #all diagonals in one list\n",
    "A = diags(diagonals,[0,1,-1]) # sparse matrix with scipy using above list\n",
    "b = np.asarray([8 if (i ==0 or i == dim-1) else 7 for i in range(dim)]) # b = [8,7,...,7,8]\n",
    "print(b)\n",
    "print(b.shape)\n",
    "x0= np.asarray([0.5 for i in range(dim)]) # x0 = 1/2... ή 0.5\n",
    "print(x0.shape)\n",
    "A.todense()\n",
    "A = A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-35001.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Solution for x = 1...1\n",
    "\n",
    "x_solution = np.asarray([1 for i in range(dim)])\n",
    "minimum = f_x(x_solution,A,b)\n",
    "minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding eivenvalues of A\n",
    "\n",
    "#### 1st way, calculation via eigsh function from library scipy.sparse using matrix. It can return only 1 eigenvalue , largest or smallest, whatever we choose:  (lmax - lmin) / (lmax + lmin) = 0.22222...\n",
    "\n",
    "#### 2nd way using calculations of numerical2.pdf page 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"myimage.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"myimage.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sparse = diags(diagonals,[0,1,-1]) # sparse matrix με scipy\n",
    "\n",
    "eigenvalues_max, _ = eigsh(A_sparse, k=1,which='LM')\n",
    "eigenvalues_min, _ = eigsh(A_sparse, k=1,which='SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues_min[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving eigenvalues so that we dont execute above commands again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22222221126768257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues_max = 10.999999901457116\n",
    "eigenvalues_min = 7.000000098621385\n",
    "\n",
    "#((λmax + λmin) / (λmax - λmin))\n",
    "myvalue = (eigenvalues_max - eigenvalues_min  ) / (eigenvalues_max+ eigenvalues_min )\n",
    "myvalue\n",
    "\n",
    "# |Χ0- Χ_bar|A\n",
    "#np.sqrt(np.dot(np.dot((x0-xnew).T,A),x0-xnew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Algorithm for square function\n",
    "\n",
    "Algorithm was executed for 20 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "r = b - np.dot(A,x0)\n",
    "a = np.dot(r.T,r) / np.dot(np.dot(A,r),r.T)\n",
    "xold = x0\n",
    "xnew = xold + a*r\n",
    "k=0\n",
    "error = (myvalue**k)*np.sqrt(np.dot(np.dot((xold-xnew).T,A),xold-xnew))\n",
    "while error > 10**-10:\n",
    "    r = r - a*np.dot(A,r)\n",
    "    a = np.dot(r.T,r) / np.dot(np.dot(A,r),r.T)\n",
    "    xold = xnew\n",
    "    xnew = xold + a*r\n",
    "    k+=1\n",
    "    error = (myvalue**k)*np.sqrt(np.dot(np.dot((x0-xnew).T,A),x0-xnew))\n",
    "print(k)\n",
    "print(xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the F value , when inserting the solution from gradient descent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1343687914900205e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-35001.00000000001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(error)\n",
    "sol1 = f_x(xnew,A,b)\n",
    "sol1\n",
    "#print(abs(f_x(x_solution,A,b) - f_x(xnew,A,b)) < 1e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjugated gradient method\n",
    "\n",
    "This method converged in 19 iterations too. The benefit of this method is that we know that in certain number of steps we get a convergence(in at least n steps). Also this method is a matrix - free method. Finally we can see that we will have less error between real solution and the converged than in the first algorithm. That is because error in conjugated gradient method from theorem 15 says that:\n",
    "\n",
    "       e_k = xk - x_bar , ||e_k|| <= (2r^k)/(1 + r^(2k))||e_0||_{A}\n",
    "       \n",
    "       where r = sqrt(K2(A)-1) / sqrt(K2(A)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "r = b - np.dot(A,x0)\n",
    "p = r\n",
    "a = np.dot(p.T,r) / np.dot(np.dot(A,p),p.T)\n",
    "xold = x0\n",
    "xnew = xold + a*p\n",
    "k=0\n",
    "error2 = (myvalue**k)*np.sqrt(np.dot(np.dot((xold-xnew).T,A),xold-xnew))\n",
    "while error2 > 10**-10:\n",
    "    r = r - a*np.dot(A,p)\n",
    "    betas = np.dot(np.dot(A,p).T,r)/np.dot(np.dot(A,p).T, p)\n",
    "    p = r - np.dot(betas,p)\n",
    "    a = np.dot(p.T,r) / np.dot(np.dot(A,p),p.T)\n",
    "    xold = xnew\n",
    "    xnew = xold + a*p\n",
    "    k+=1\n",
    "    error2 = (myvalue**k)*np.sqrt(np.dot(np.dot((x0-xnew).T,A),x0-xnew))\n",
    "print(k)\n",
    "print(xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking F value with new solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1343687914900185e-11\n",
      "-35001.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(error2)\n",
    "sol2 = f_x(xnew,A,b)\n",
    "print(sol2)\n",
    "print(abs(f_x(x_solution,A,b) - f_x(xnew,A,b)) < 1e-323) # very small error.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of 2 solutions  - Conclusions\n",
    "    We can see that the 2nd method converged to a better solution\n",
    "    Both algorithms needed 19 iterations to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between 1st method and solution :  7.275957614183426e-12\n",
      "Difference between 2st method and solution :  0.0\n"
     ]
    }
   ],
   "source": [
    "#1st solution\n",
    "print(\"Difference between 1st method and solution : \",abs(minimum - sol1))\n",
    "#2nd solution\n",
    "print(\"Difference between 2st method and solution : \",abs(minimum - sol2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(minimum - sol1) < abs(minimum - sol2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating k , with formula [(lmax - lmin) / (lmax + lmin)]^k * ||Xo-X_bar||_norm(A) <= tol, where tol = 10**-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = round(np.log((10**-10) / np.sqrt(np.dot(np.dot((x0-x_solution).T,A),x0-x_solution))) / np.log(myvalue))\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need 19 iterations to converge to the best solution using tolerance = 10**10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
